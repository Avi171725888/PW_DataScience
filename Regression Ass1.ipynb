{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31443f27-fa02-43be-afe6-3c740855db5c",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f02b5-d46d-43c9-9be8-cc03338ee0fb",
   "metadata": {},
   "source": [
    "Difference between simple linear regression and multiple linear regression.\n",
    "1.Simple linear regression has only one x and one y variable.\n",
    "2.Multiple linear regression has one y and two or more x variables.\n",
    "3.For instance, when we predict rent based on square feet alone that is simple linear regression.\n",
    "4.When we predict rent based on square feet and age of the building that is an example of multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a3309-ecb3-420d-a50a-e97b4ee9205b",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da607347-b382-4fe3-9442-93f9552e8d5f",
   "metadata": {},
   "source": [
    "There are primarily five assumptions of linear regression.They are:\n",
    "\n",
    "1.There is a linear relationship between the predictors (x) and the outcome (y)\n",
    "2.Predictors (x) are independent and observed with negligible error\n",
    "3.Residual Errors have a mean value of zero\n",
    "4.Residual Errors have constant variance\n",
    "5.Residual Errors are independent from each other and predictors (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a88cb03-7e11-4f56-bdee-4f613bd21301",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3375b-05b4-46c9-800d-4588fd4aab93",
   "metadata": {},
   "source": [
    "When modeling linear data, the slope and intercept of the graph provide useful information about the initial conditions and rate of change of what is being studied. First, the slope of a line is a measure of its steepness. In a line, slope is a ratio of the change in one variable to the change in the other. Usually, this refers to the change in y for each unit change in x, but sometimes other variables may be used.\n",
    "Slope is usually represented by the variable \n",
    "m=(change in y)/(change in x)\n",
    "The intercept refers to the y-intercept, which is where the line intersects the y-axis. Again, other variables may be used, but the intercept generally refers to the independent variable and the vertical axis.\n",
    "Example:-\n",
    "Suppose that some doctors are conducting a study. They ask their patients how many servings of fruit or vegetables they consume per day. They also keep track of whether those patients are obese. They record the percentage of their patients who consume 5 or more servings of fruits and vegetables per day and the percentage of their patients who are obese. The data is shown in the graph below.\n",
    "The equation of the regression line is given to be y = -0.91x + 38.42.\n",
    "The slope is -0.91. The units of y are % of adults and the units of x are also % of adults. The units of y and the units of x will cancel out when they are divided. Instead, to interpret the slope, state that the percentage of obese adults decreases by 0.91% for every 1% increase in the number of adults who are getting 5 or more servings of fruits and vegetables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55a21f-53b7-403d-8cdb-6c8db5496dc3",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a2848-6740-4afe-9f9d-6fd84740d574",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks.  Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates. Until the function is close to or equal to zero, the model will continue to adjust its parameters to yield the smallest possible error. Once machine learning models are optimized for accuracy, they can be powerful tools for artificial intelligence (AI) and computer science applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad8e34-2bec-4a13-b6ca-11e02563b846",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf9c011-e5e5-4e31-b5ac-422bacc8d1f0",
   "metadata": {},
   "source": [
    "Multiple linear regression is used to estimate the relationship between two or more independent variables and one dependent variable. You can use multiple linear regression when you want to know:\n",
    "\n",
    "1.How strong the relationship is between two or more independent variables and one dependent variable (e.g. how rainfall, temperature, and amount of fertilizer added affect crop growth).\n",
    "2.The value of the dependent variable at a certain value of the independent variables (e.g. the expected yield of a crop at certain levels of rainfall, temperature, and fertilizer addition)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a6bd2e-40f6-4db3-89af-7c06f8d45d3f",
   "metadata": {},
   "source": [
    "Difference between simple linear regression and multiple linear regression.\n",
    "1.Simple linear regression has only one x and one y variable.\n",
    "2.Multiple linear regression has one y and two or more x variables.\n",
    "3.For instance, when we predict rent based on square feet alone that is simple linear regression.\n",
    "4.When we predict rent based on square feet and age of the building that is an example of multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e6a61-573e-479a-9fb4-761a9f63b64b",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7cb3a6-5456-4e43-8a87-e04436a525d5",
   "metadata": {},
   "source": [
    "Multicollinearity is a statistical phenomenon that occurs when two or more independent variables in a regression model are highly correlated with each other. In other words, multicollinearity indicates a strong linear relationship among the predictor variables. This can create challenges in the regression analysis because it becomes difficult to determine the individual effects of each independent variable on the dependent variable accurately.\n",
    "Multicollinearity can lead to unstable and unreliable coefficient estimates, making it harder to interpret the results and draw meaningful conclusions from the model. It is essential to detect and address multicollinearity to ensure the validity and robustness of regression models.\n",
    "Multicollinearity occurs when two or more independent variables in a data frame have a high correlation with one another in a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef230b-9595-4ddf-bf83-75e890320bfe",
   "metadata": {},
   "source": [
    "There are several ways to detect multicollinearity in a dataset, such as using the Variance Inflation Factor (VIF) or calculating the correlation matrix of the independent variables. To address multicollinearity, techniques such as regularization or feature selection can be applied to select a subset of independent variables that are not highly correlated with each other. In this article, we will focus on the most common one – VIF (Variance Inflation Factors).VIF score of an independent variable represents how well the variable is explained by other independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f095202-9fd1-49ec-a734-6ba5058376f9",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6254b0c5-cc4d-4f57-ba1f-e3299ae258a8",
   "metadata": {},
   "source": [
    "A simple linear regression algorithm only works when the relationship between the data is linear. But suppose we have non-linear data, then linear regression will not be able to draw a best-fit line. Simple regression analysis fails in such conditions. Consider the below diagram, which has a non-linear relationship, and you can see the linear regression results on it, which does not perform well, meaning it does not come close to reality. Hence, we introduce polynomial regression to overcome this problem, which helps identify the curvilinear relationship between independent and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63073e85-bb29-49cc-ae4d-994a00ddf586",
   "metadata": {},
   "source": [
    "Now we know how polynomial regression works and helps to build a model over non-linear data. Let’s compare both algorithms practically and see the results.\n",
    "First, we will generate the data using some equation ax^2 + bx + c, and then apply simple linear regression to it to form a linear equation. Then we will apply polynomial regression on top of it, which will make an easy comparison between the practical performance of both algorithms.\n",
    "Initially, we will try it with only one input column and one output column. After having a brief understanding we will try it on high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c108ffb-07e2-409a-bc20-1d331fc246fe",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522e38a-a058-4e7a-9b54-3fd7cbff4610",
   "metadata": {},
   "source": [
    "Polynomial regression offers several advantages over linear regression:\n",
    "1.Non-linear relationships: Polynomial regression can capture non-linear relationships between variables, unlike linear regression, which assumes a linear relationship. This flexibility is helpful when the underlying relationship is curvilinear.\n",
    "2.Improved fit: By allowing for more flexible curve fitting, polynomial regression can often provide a better fit to the data compared to linear regression. This can help in finding the best-fitting curve among different options.\n",
    "3.Local approximation: Polynomial regression can approximate the data in a specific region more accurately by adjusting the degree of the polynomial. This enables a better fit within localized areas of the dataset.\n",
    "4.Versatility: Polynomial regression can handle a wide range of functions by adjusting the degree of the polynomial. It allows for modeling complex relationships without needing to use more advanced techniques.\n",
    "5.Interactions: Polynomial regression can account for interactions between different predictor variables by including interaction terms in the polynomial equation. This allows for better understanding and modeling of complex interaction effects.\n",
    "Polynomial regression provides additional flexibility and accuracy in modeling non-linear relationships, local approximations, and interactions. However, it's important to strike a balance between complexity and overfitting the data to avoid misleading results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
